<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FSAnalyser ‚Äî File Server Analysis Tool</title>
    <style>
        :root {
            --brand: #1e3a5f;
            --accent: #2c5282;
            --green: #28a745;
            --amber: #e67e22;
            --red: #dc3545;
            --gray: #6c757d;
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: "Segoe UI", -apple-system, BlinkMacSystemFont, sans-serif;
            color: #2d3748;
            background: #f7fafc;
            line-height: 1.7;
        }

        .header {
            background: linear-gradient(135deg, var(--brand) 0%, var(--accent) 100%);
            color: white;
            padding: 3rem 2rem;
            text-align: center;
        }

        .header h1 {
            font-size: 2.2rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        .header .subtitle {
            font-size: 1.1rem;
            opacity: 0.9;
        }

        .header .attribution {
            margin-top: 0.35rem;
            font-size: 0.92rem;
            opacity: 0.9;
        }

        .header .badge {
            display: inline-block;
            margin-top: 1rem;
            background: rgba(255, 255, 255, 0.2);
            padding: 0.4rem 1.2rem;
            border-radius: 20px;
            font-size: 0.85rem;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem 1.5rem;
        }

        .section {
            background: white;
            border-radius: 10px;
            padding: 2rem;
            margin: 1.5rem 0;
            box-shadow: 0 1px 4px rgba(0, 0, 0, 0.06);
        }

        .section h2 {
            color: var(--brand);
            font-size: 1.35rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #e2e8f0;
        }

        .section h3 {
            color: var(--accent);
            font-size: 1.05rem;
            margin: 1.2rem 0 0.5rem;
        }

        .section p {
            margin-bottom: 0.8rem;
        }

        .section ul,
        .section ol {
            margin: 0.5rem 0 1rem 1.5rem;
        }

        .section li {
            margin-bottom: 0.4rem;
        }

        .callout {
            border-radius: 8px;
            padding: 1rem 1.2rem;
            margin: 1rem 0;
            font-size: 0.95rem;
        }

        .callout-green {
            background: #d4edda;
            border-left: 4px solid var(--green);
        }

        .callout-amber {
            background: #fff3cd;
            border-left: 4px solid var(--amber);
        }

        .callout-red {
            background: #f8d7da;
            border-left: 4px solid var(--red);
        }

        .callout-blue {
            background: #cfe2ff;
            border-left: 4px solid #0d6efd;
        }

        .callout>strong:first-child {
            display: block;
            margin-bottom: 0.3rem;
        }

        .grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 1rem;
            margin: 1rem 0;
        }

        @media (max-width: 700px) {
            .grid {
                grid-template-columns: 1fr;
            }
        }

        .grid-item {
            background: #f7fafc;
            border-radius: 8px;
            padding: 1rem 1.2rem;
            border: 1px solid #e2e8f0;
        }

        .grid-item .icon {
            font-size: 1.5rem;
            margin-bottom: 0.3rem;
        }

        .grid-item .title {
            font-weight: 600;
            color: var(--brand);
            margin-bottom: 0.3rem;
        }

        .grid-item p {
            font-size: 0.9rem;
            color: #4a5568;
            margin: 0;
        }

        .report-preview {
            background: #f7fafc;
            border: 1px solid #e2e8f0;
            border-radius: 8px;
            padding: 1.2rem;
            margin: 1rem 0;
        }

        .report-preview .row {
            display: flex;
            justify-content: space-between;
            padding: 0.5rem 0;
            border-bottom: 1px solid #edf2f7;
            font-size: 0.92rem;
        }

        .report-preview .row:last-child {
            border: none;
        }

        .report-preview .label {
            color: var(--gray);
        }

        .report-preview .value {
            font-weight: 600;
            color: var(--brand);
        }

        .tag {
            display: inline-block;
            padding: 0.15rem 0.6rem;
            border-radius: 12px;
            font-size: 0.78rem;
            font-weight: 600;
            margin: 0.1rem 0.2rem;
        }

        .tag-green {
            background: #d4edda;
            color: var(--green);
        }

        .tag-amber {
            background: #fff3cd;
            color: #856404;
        }

        .tag-red {
            background: #f8d7da;
            color: var(--red);
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 0.8rem 0;
            font-size: 0.9rem;
        }

        th {
            background: #f7fafc;
            text-align: left;
            padding: 0.6rem 0.8rem;
            font-weight: 600;
            color: #4a5568;
            border-bottom: 2px solid #e2e8f0;
        }

        td {
            padding: 0.5rem 0.8rem;
            border-bottom: 1px solid #edf2f7;
        }

        footer {
            text-align: center;
            padding: 2rem;
            color: var(--gray);
            font-size: 0.8rem;
        }

        @media print {
            body {
                background: white;
            }

            .section {
                box-shadow: none;
                border: 1px solid #e2e8f0;
                break-inside: avoid;
            }

            .header {
                padding: 2rem;
            }
        }
    </style>
</head>

<body>

    <div class="header">
        <h1>FSAnalyser</h1>
        <div class="subtitle">Windows File Server Analysis & Inventory Tool</div>
        <div class="attribution">Prepared by Steve Watson</div>
        <div class="badge">Read-Only &bull; Non-Destructive &bull; Single Application &bull; Runs Locally on Each Server
        </div>
    </div>

    <div class="container">

        <!-- ============================================================ -->
        <div class="section">
            <h2>What Is This?</h2>
            <p>FSAnalyser is a lightweight analysis tool that scans Windows file servers and produces a detailed
                report showing what data exists, how it is organised, who has access, and where optimization
                opportunities exist.</p>
            <p>It functions as a comprehensive inventory and health check. The output provides the evidence needed
                to plan migrations, security audits, storage optimization, and compliance reviews with complete
                visibility into file server contents and permissions.</p>

            <div class="callout callout-green">
                <strong>üîí Safety Guarantee ‚Äî Strictly Read-Only</strong>
                FSAnalyser operates in <strong>strict read-only mode</strong>. It does not modify, move, delete, or
                lock any files or folders. It does not write anything to the drives being scanned ‚Äî all output
                (database, CSV exports, and report) is written to a separate output folder that you choose.
                The scanned data volumes are never altered in any way.
                It is a single application with a graphical interface ‚Äî there is
                nothing to install and nothing to uninstall afterwards. In metadata-only mode the impact is typically
                low; optional content
                hashing is more I/O intensive and is best scheduled off-peak.
                It reads the same information that Windows Explorer reads when you browse a folder ‚Äî just
                faster and more systematically.
            </div>
        </div>

        <!-- ============================================================ -->
        <div class="section">
            <h2>What Does It Actually Do?</h2>
            <p>FSAnalyser is delivered as a single application with a point-and-click interface that runs
                <strong>directly
                    on
                    each file server</strong>. There is no remote scanning, no network overhead for file enumeration,
                and no agent or software to install. The system <strong>automatically detects</strong> local drives,
                domain controller, and DFS namespaces ‚Äî pre-filling the form for immediate execution. The scan runs
                in up to eleven automated stages:

            <div class="grid">
                <div class="grid-item">
                    <div class="icon">üñß</div>
                    <div class="title">1. Discover Shares</div>
                    <p>Finds every SMB share on the local server, including hidden shares (e.g. Finance$), and records
                        who has share-level permissions.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">üîó</div>
                    <div class="title">2. Map DFS Namespaces</div>
                    <p>Discovers all DFS links and where they point, identifying data that may be accessible via
                        multiple paths.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">üìÇ</div>
                    <div class="title">3. Inventory Every File</div>
                    <p>Walks the entire folder tree recording file name, size, type, dates, and NTFS attributes
                        (including EFS encryption and reparse point flags) for every item.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">üîê</div>
                    <div class="title">4. Read Security Permissions</div>
                    <p>Reads the NTFS access control lists (ACLs) on every folder to understand exactly who can access
                        what.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">üë•</div>
                    <div class="title">5. Resolve AD Identities</div>
                    <p>Looks up every user and group found in the permissions against Active Directory to get real names
                        and group memberships. This is the only stage that generates network traffic (LDAP queries to a
                        domain controller).</p>
                </div>
                <div class="grid-item">
                    <div class="icon">üíö</div>
                    <div class="title">6. Check Group Health</div>
                    <p>Identifies security groups that have no enabled members ‚Äî "dead groups" that grant access to
                        nobody but clutter permissions.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">üîì</div>
                    <div class="title">7. Detect Open Files</div>
                    <p>Uses the Windows Server API to identify files currently open by users. Helps plan migration
                        cutover ‚Äî open files may fail to copy. Requires running elevated (Administrator).</p>
                </div>
                <div class="grid-item">
                    <div class="icon">#Ô∏è‚É£</div>
                    <div class="title">8. Content Hashing (optional)</div>
                    <p>Reads file contents and computes SHA-256 hashes for exact duplicate detection. Only runs when
                        the "Hash file contents" option is ticked. This is the only stage that reads file content.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">üìé</div>
                    <div class="title">9. Alternate Data Streams (optional)</div>
                    <p>Enumerates hidden NTFS alternate data streams attached to files. These are invisible in Explorer
                        but consume space and will be lost during migration. Only runs when the
                        "Scan Alternate Data Streams" option is ticked.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">üìä</div>
                    <div class="title">10. Export Raw Data</div>
                    <p>Produces up to 21 CSV files covering every dimension of the analysis so the data can be
                        loaded into Excel or Power BI for further review.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">üìã</div>
                    <div class="title">11. Generate Report</div>
                    <p>Produces a self-contained HTML report with colour-coded charts, tables, and clear status
                        indicators ‚Äî no software needed to view it.</p>
                </div>
            </div>

            <div class="callout callout-blue">
                <strong>üí° Network Traffic</strong>
                Because FSAnalyser runs locally on the file server, all file and folder enumeration is local disk I/O ‚Äî
                there is <strong>no SMB network traffic</strong>. The only network traffic is LDAP queries to
                Active Directory during stages 5‚Äì6, which is lightweight (a few MB at most).
            </div>
        </div>

        <!-- ============================================================ -->
        <div class="section">
            <h2>Scan Control &mdash; Stop, Pause &amp; Resume</h2>
            <p>FSAnalyser provides full control over long-running scans, making it practical for very large
                file servers where a complete scan may take minutes or hours:</p>

            <div class="grid">
                <div class="grid-item">
                    <div class="icon">&#x23F9;&#xFE0F;</div>
                    <div class="title">Immediate Stop</div>
                    <p>The Stop button cancels the scan within seconds. All data collected so far is safely
                        committed to the database &mdash; nothing is lost. Workers across all parallel threads
                        respond cooperatively to the cancel signal.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">&#x23F8;&#xFE0F;</div>
                    <div class="title">Pause &amp; Resume</div>
                    <p>The Pause button temporarily suspends all scan activity. Worker threads block safely
                        until Resume is pressed. Useful for reducing disk I/O during busy periods, then
                        continuing without restarting.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">&#x1F504;</div>
                    <div class="title">Resume on Restart</div>
                    <p>If the scan is stopped, the application is closed, or the server is rebooted, simply
                        run the tool again pointing to the same output folder. Completed stages are automatically
                        skipped, and partially-completed stages (such as content hashing) resume from where
                        they left off &mdash; files already processed are not re-scanned.</p>
                </div>
                <div class="grid-item">
                    <div class="icon">&#x2728;</div>
                    <div class="title">Fresh Scan Option</div>
                    <p>Tick the &ldquo;Fresh scan&rdquo; checkbox to clear all previous state and start over
                        from scratch. This removes the stored progress and database, ensuring a completely
                        clean run.</p>
                </div>
            </div>

            <div class="callout callout-green">
                <strong>&#x1F6E1;&#xFE0F; Safe by Design</strong>
                All database writes use transactions with idempotent inserts. Stopping or pausing at any point
                &mdash; even mid-write &mdash; cannot corrupt the database. The scan can always be safely resumed from
                its last checkpoint.
            </div>
        </div>

        <!-- ============================================================ -->
        <div class="section">
            <h2>CSV Exports &mdash; Raw Data for Excel &amp; Power BI</h2>
            <p>In addition to the HTML report, FSAnalyser produces up to 21 individual CSV files containing the
                full raw data behind every report section. These are designed for import into Excel, Power BI, or
                any other analytics tool. Only CSVs with data are produced ‚Äî empty exports are automatically skipped.
            </p>

            <table>
                <tr>
                    <th>CSV File</th>
                    <th>Contents</th>
                </tr>
                <tr>
                    <td><strong>cold_data_by_folder.csv</strong></td>
                    <td>Top-level folder breakdown showing file count and size in each age band (current, 1‚Äì2 yr, 2‚Äì5
                        yr, 5‚Äì7 yr, 7+ yr)</td>
                </tr>
                <tr>
                    <td><strong>stale_files.csv</strong></td>
                    <td>Individual files not modified in over 2 years ‚Äî path, size, and last modified date</td>
                </tr>
                <tr>
                    <td><strong>unpublished.csv</strong></td>
                    <td>Top-level folders that are not accessible through any SMB share or DFS link</td>
                </tr>
                <tr>
                    <td><strong>acl_complexity.csv</strong></td>
                    <td>Folders ranked by permission complexity ‚Äî unique ACE count, direct user grants, and inheritance
                        status</td>
                </tr>
                <tr>
                    <td><strong>principals.csv</strong></td>
                    <td>Every domain user and group found in NTFS permissions, with AD display name and type</td>
                </tr>
                <tr>
                    <td><strong>group_health.csv</strong></td>
                    <td>AD group health analysis ‚Äî total members, enabled members, and whether the group is effectively
                        dead</td>
                </tr>
                <tr>
                    <td><strong>duplicates.csv</strong></td>
                    <td>Duplicate file clusters (same hash or same size+type), showing every file path and wasted bytes
                    </td>
                </tr>
                <tr>
                    <td><strong>compressed_files.csv</strong></td>
                    <td>Every NTFS-compressed file ‚Äî path, compressed size, and original size</td>
                </tr>
                <tr>
                    <td><strong>file_types.csv</strong></td>
                    <td>Complete file extension breakdown ‚Äî extension, file count, and total size per type</td>
                </tr>
                <tr>
                    <td><strong>folder_breakdown.csv</strong></td>
                    <td>Storage consumed by each top-level folder ‚Äî file count, folder count, and total size</td>
                </tr>
                <tr>
                    <td><strong>sp_compatibility.csv</strong></td>
                    <td>Every file that would fail a SharePoint upload ‚Äî path, issue type (long path, illegal
                        characters, blocked extension, oversized)</td>
                </tr>
                <tr>
                    <td><strong>efs_files.csv</strong></td>
                    <td>Every EFS-encrypted file ‚Äî full path and size</td>
                </tr>
                <tr>
                    <td><strong>reparse_points.csv</strong></td>
                    <td>All symbolic links and junction points ‚Äî path, type, and target</td>
                </tr>
                <tr>
                    <td><strong>churn_by_month.csv</strong></td>
                    <td>Monthly file modification counts and volume for trend analysis</td>
                </tr>
                <tr>
                    <td><strong>permission_mapping.csv</strong></td>
                    <td>Per-folder permission mapping suggestions for SharePoint migration (simple / moderate / complex)
                    </td>
                </tr>
                <tr>
                    <td><strong>open_files.csv</strong></td>
                    <td>Files that were open/locked by users at scan time ‚Äî path, username, and lock type</td>
                </tr>
                <tr>
                    <td><strong>alternate_data_streams.csv</strong></td>
                    <td>Hidden NTFS alternate data streams ‚Äî host file path, stream name, and size</td>
                </tr>
            </table>

            <div class="callout callout-blue">
                <strong>üí° Tip</strong>
                CSV files use UTF-8 encoding with a BOM header for reliable opening in Excel. Each file has
                column headers in the first row. Files are only created when data exists ‚Äî you won't see
                empty CSV files cluttering the output folder.
            </div>
        </div>

        <!-- ============================================================ -->
        <div class="section">
            <h2>What Will the Report Show?</h2>
            <p>The report is designed to answer the key questions that come up in every SharePoint migration planning
                exercise:</p>

            <h3>üìê How Much Data Do We Have?</h3>
            <p>Total file count, folder count, and storage consumed ‚Äî broken down by top-level folder, file type, and
                file size range. You'll see at a glance which departments own the most data and what types of files
                dominate (documents, images, executables, etc.).</p>

            <div class="report-preview">
                <div class="row"><span class="label">Total Items</span><span class="value">2,045,491</span></div>
                <div class="row"><span class="label">Total Size</span><span class="value">357.9 GB</span></div>
                <div class="row"><span class="label">Top file types</span><span class="value">.docx, .xlsx, .pdf, .pptx,
                        .jpg, .png</span></div>
            </div>

            <h3>‚ùÑÔ∏è How Much of It Is Cold (Unused)?</h3>
            <p>Files are grouped by how recently they were last modified: current (under 1 year), ageing (1‚Äì2 years),
                stale (2‚Äì5 years), and archive (5+ years). A colour-coded stacked bar shows the split instantly. Cold
                data is the single biggest opportunity ‚Äî <strong>data that nobody has touched in years does not need to
                    be migrated to premium SharePoint storage</strong>.</p>

            <h3>üìã Are There Duplicates?</h3>
            <p>The report identifies clusters of files that are likely duplicates (same file type and exact same file
                size appearing 3 or more times). It calculates the total wasted storage and highlights the worst
                offenders. When the "Hash file contents" option is ticked, the tool also performs
                <strong>exact duplicate detection</strong> by computing SHA-256 hashes, confirming which files are
                truly identical down to the byte.
            </p>

            <h3>üîí Is There Unpublished Data?</h3>
            <p>Not all data on a file server is necessarily shared with users. The report compares the folder structure
                against SMB shares and DFS links, highlighting any top-level folders that are <strong>not accessible
                    through any share or DFS path</strong>. This could be orphaned data, backup copies, or folders that
                were removed from shares but never cleaned up.</p>

            <h3>üîê How Complex Are the Permissions?</h3>
            <p>SharePoint handles permissions very differently from NTFS. The report shows how many distinct access
                control lists exist across folders, flags folders with unusually high complexity (many unique permission
                entries), and highlights where individual users have been given direct permissions instead of going
                through groups ‚Äî a pattern that is hard to migrate cleanly.</p>

            <h3>üíö Are AD Groups Healthy?</h3>
            <p>The report checks every security group referenced in the file server permissions and verifies it against
                Active Directory. Groups with no enabled members ("dead groups") are flagged ‚Äî these are groups that
                appear in permissions but effectively grant access to nobody. Cleaning these up before migration
                simplifies the permission model significantly.</p>

            <h3>üñß Share and DFS Overview</h3>
            <p>A complete inventory of every SMB share (including hidden admin shares) and every DFS link, with their
                paths and permissions, so you have a full picture of how users currently access the data.</p>

            <h3>üéØ SharePoint Compatibility Check</h3>
            <p>The report automatically flags files that would <strong>fail to upload to SharePoint</strong>:
                paths exceeding 400 characters, illegal characters in names (<code># % * : &lt; &gt; ? |</code>),
                blocked file extensions, and files exceeding 250 GB. Each issue is categorised by severity so
                remediation can be prioritised.</p>

            <h3>üîì EFS Encrypted Files &amp; Reparse Points</h3>
            <p>Files encrypted with NTFS EFS and items with reparse points (symbolic links, junction points) are
                automatically detected from file attributes. EFS files cannot be migrated without decryption;
                junctions and symlinks may cause data to be counted twice or create circular references.</p>

            <h3>üì° Migration Bandwidth Estimation</h3>
            <p>Based on the total data volume, the report estimates migration time at three speeds: LAN (1 Gbps),
                WAN (100 Mbps), and SharePoint-throttled (~200 Mbps effective). This helps schedule realistic
                cutover windows.</p>

            <h3>üìà Data Churn &amp; User Activity</h3>
            <p>The report analyses how recently files were modified (last 30 days, 90 days, 1 year) and provides
                monthly modification trends. Highly active folders may need a delta-sync migration approach.
                Where access timestamps are available, the report also shows user activity distribution.</p>

            <h3>üó∫Ô∏è Permission Mapping Suggestions</h3>
            <p>For each top-level folder, the report analyses ACL complexity and suggests how it might map to
                SharePoint permission levels ‚Äî simple (single group), moderate (2‚Äì3 levels), or complex
                (requiring manual flattening). This gives a starting point for permission planning.</p>

            <h3>üîì Open Files at Scan Time</h3>
            <p>When run elevated, the report shows which files were locked/open by users at scan time, along with
                the username and access type. These files need special handling during migration cutover.</p>

            <h3>Overall Health Score</h3>
            <p>The report header includes an overall health badge ‚Äî <span class="tag tag-green">Healthy</span> <span
                    class="tag tag-amber">Needs Attention</span> or <span class="tag tag-red">Critical</span> ‚Äî based on
                the percentage of cold data, duplicate waste, SharePoint compatibility issues, and dead groups found.
            </p>

            <div class="callout callout-blue">
                <strong>üìä Example Report</strong>
                See a complete example of the HTML report produced by FSAnalyser:
                <a href="https://swatto.co.uk/FSAnalyser-ReportExample.html" target="_blank" rel="noopener"
                    style="color:#0d6efd; font-weight:600;">View Example Report ‚Üí</a>
            </div>
        </div>

        <!-- ============================================================ -->
        <div class="section">
            <h2>Key Savings Opportunities</h2>
            <p>Based on typical file server assessments, the report will help quantify savings in these areas:</p>

            <table>
                <tr>
                    <th>Opportunity</th>
                    <th>Typical Savings</th>
                    <th>How We Identify It</th>
                </tr>
                <tr>
                    <td><strong>Cold data exclusion</strong></td>
                    <td>30‚Äì60% of total storage</td>
                    <td>Files not modified in 2+ years ‚Äî archive or delete instead of migrating to SharePoint</td>
                </tr>
                <tr>
                    <td><strong>Duplicate elimination</strong></td>
                    <td>5‚Äì15% of total storage</td>
                    <td>Same-size, same-type file clusters appearing across multiple folders</td>
                </tr>
                <tr>
                    <td><strong>Orphaned/unpublished data</strong></td>
                    <td>Varies</td>
                    <td>Folders on disk that no user can reach via any share ‚Äî often forgotten data</td>
                </tr>
                <tr>
                    <td><strong>Permission simplification</strong></td>
                    <td>Reduced migration effort</td>
                    <td>Dead groups and direct user ACEs that can be cleaned up before migration</td>
                </tr>
                <tr>
                    <td><strong>Empty files &amp; tiny files</strong></td>
                    <td>Clutter reduction</td>
                    <td>Zero-byte files and files under 1 KB that may be temporary or broken</td>
                </tr>
            </table>
        </div>

        <!-- ============================================================ -->
        <div class="section">
            <h2>Safety &amp; Impact on Production</h2>

            <div class="callout callout-green">
                <strong>‚úÖ What the tool DOES:</strong>
                <ul style="margin-top:0.3rem;">
                    <li>Reads file and folder metadata (name, size, dates, attributes) from local disk</li>
                    <li>Reads NTFS security descriptors (permissions)</li>
                    <li>Reads SMB share configurations and DFS namespace structures</li>
                    <li>Queries Active Directory for user and group details (read-only lookups ‚Äî the only network
                        traffic)</li>
                    <li>Detects currently open/locked files via Windows Server APIs (requires running as Administrator)
                    </li>
                    <li>Optionally reads file contents to compute hashes for exact duplicate detection</li>
                    <li>Optionally enumerates NTFS alternate data streams</li>
                    <li>Stores all findings in a local database and CSV exports on the same server</li>
                </ul>
            </div>

            <div class="callout callout-red">
                <strong>üö´ What the tool DOES NOT do:</strong>
                <ul style="margin-top:0.3rem;">
                    <li>Does not modify, move, rename, or delete any file or folder ‚Äî <strong>100% read-only</strong>
                    </li>
                    <li>Does not write anything to the drives being scanned ‚Äî all output goes to a separate folder</li>
                    <li>Does not change any permissions, shares, or DFS configuration</li>
                    <li>Does not require installation ‚Äî it is a single portable application</li>
                    <li>Does not lock files or prevent user access</li>
                    <li>Does not modify Active Directory in any way ‚Äî only read-only LDAP lookups</li>
                    <li>Does not send data anywhere ‚Äî all output is local files on the server</li>
                </ul>
            </div>

            <p><strong>Performance impact:</strong> Because the application runs locally, all file enumeration is
                direct disk I/O with no network overhead. In a benchmark dataset of 2 million files (358 GB), the
                inventory stage completed in under 35 seconds on local NVMe. Real production times vary by file count,
                storage speed, ACL complexity, and AD responsiveness. The optional content hashing feature does read
                file contents,
                which will generate sustained disk read activity ‚Äî this is best scheduled outside business hours on busy
                servers. All other stages have minimal I/O impact and are safe to run at any time.</p>
        </div>

        <!-- ============================================================ -->
        <div class="section">
            <h2>Estimated Runtime by Data Volume (TB)</h2>
            <p>The key point is that runtime is driven by <strong>file count and disk
                    throughput</strong>
                more than TB alone. Many small files take longer than fewer large files, even at the same total TB.</p>

            <div class="callout callout-blue">
                <strong>Planning assumptions</strong>
                The ranges below are practical planning bands for production servers. They include metadata,
                permissions,
                and reporting overhead. Optional content hashing adds substantial extra read time.
            </div>

            <table>
                <tr>
                    <th>Data Volume</th>
                    <th>Metadata-Only Scan</th>
                    <th>With Focused Hashing</th>
                    <th>With Full Hashing</th>
                </tr>
                <tr>
                    <td><strong>1 TB</strong></td>
                    <td>15‚Äì60 minutes</td>
                    <td>30 minutes ‚Äì 3 hours</td>
                    <td>2‚Äì8 hours</td>
                </tr>
                <tr>
                    <td><strong>5 TB</strong></td>
                    <td>1‚Äì5 hours</td>
                    <td>2‚Äì12 hours</td>
                    <td>8‚Äì40 hours</td>
                </tr>
                <tr>
                    <td><strong>10 TB</strong></td>
                    <td>2‚Äì10 hours</td>
                    <td>4‚Äì24 hours</td>
                    <td>16‚Äì80 hours</td>
                </tr>
            </table>

            <p><strong>Hashing formula (best-effort):</strong> hashing time in hours is approximately total bytes to
                hash
                divided by effective read throughput in bytes per second, then divided by 3600.
                Example: 1 TB at 150 MB/s is about 1.9 hours for content reads alone, before database and report
                overhead.</p>

            <div class="callout callout-amber">
                <strong>Recommended execution model</strong>
                Run metadata-only scans first (fast, low risk), then run focused/full hashing as a second pass during an
                overnight window if exact duplicate evidence is required.
            </div>
        </div>

        <!-- ============================================================ -->
        <div class="section">
            <h2>Advanced Capabilities</h2>
            <p>In addition to the core inventory, the following advanced analysis features are included and appear
                automatically in the report:</p>

            <table>
                <tr>
                    <th>Capability</th>
                    <th>What It Does</th>
                    <th>Status</th>
                </tr>
                <tr>
                    <td><strong>SharePoint compatibility</strong></td>
                    <td>Flags files with paths over 400 characters, illegal characters, blocked extensions, and
                        files over 250 GB ‚Äî everything that would fail a SharePoint upload.</td>
                    <td><span class="tag tag-green">Included</span></td>
                </tr>
                <tr>
                    <td><strong>Content-based deduplication</strong></td>
                    <td>SHA-256 hashing of file contents for exact duplicate detection. Confirms which files are
                        truly identical, not just same-size. Enabled by ticking a checkbox in the application.</td>
                    <td><span class="tag tag-green">Included (opt-in)</span></td>
                </tr>
                <tr>
                    <td><strong>Open/locked file detection</strong></td>
                    <td>Detects files currently open by users at scan time, showing username and lock type.
                        Helps plan migration cutover for actively-used files. Runs automatically when elevated.</td>
                    <td><span class="tag tag-green">Included</span></td>
                </tr>
                <tr>
                    <td><strong>Permission mapping suggestions</strong></td>
                    <td>Analyses ACL complexity per folder and suggests how NTFS permissions could map to
                        SharePoint permission levels (simple / moderate / complex).</td>
                    <td><span class="tag tag-green">Included</span></td>
                </tr>
                <tr>
                    <td><strong>Cross-server duplicate detection</strong></td>
                    <td>Compares two completed scan databases and identifies duplicates across servers by matching
                        content hashes. Available via the CLI <strong>compare-db</strong> command, which generates
                        <strong>cross_server_duplicates.csv</strong> and <strong>cross_server_duplicates.html</strong>.
                    </td>
                    <td><span class="tag tag-green">Included (CLI)</span></td>
                </tr>
                <tr>
                    <td><strong>EFS encrypted files</strong></td>
                    <td>Automatically flags files with the NTFS encryption attribute set. These cannot be
                        migrated without decryption by the key holder.</td>
                    <td><span class="tag tag-green">Included</span></td>
                </tr>
                <tr>
                    <td><strong>Symbolic links &amp; junctions</strong></td>
                    <td>Detects NTFS reparse points (junctions and symlinks) that could cause data to be
                        counted twice or create circular references. SharePoint does not support these.</td>
                    <td><span class="tag tag-green">Included</span></td>
                </tr>
                <tr>
                    <td><strong>Alternate Data Streams</strong></td>
                    <td>Enumerates hidden NTFS data streams (e.g. Zone.Identifier, macOS resource forks).
                        These consume space but will be lost during migration. Enabled by ticking a checkbox in the
                        application.</td>
                    <td><span class="tag tag-green">Included (opt-in)</span></td>
                </tr>
                <tr>
                    <td><strong>Bandwidth estimation</strong></td>
                    <td>Estimates migration time at three speeds: LAN (1 Gbps), WAN (100 Mbps), and
                        SharePoint-throttled (~200 Mbps). Helps schedule realistic cutover windows.</td>
                    <td><span class="tag tag-green">Included</span></td>
                </tr>
                <tr>
                    <td><strong>Data churn rate</strong></td>
                    <td>Analyses modification patterns (30-day, 90-day, yearly) with monthly trends.
                        Highly active folders may need delta-sync migration rather than bulk copy.</td>
                    <td><span class="tag tag-green">Included</span></td>
                </tr>
                <tr>
                    <td><strong>User activity analysis</strong></td>
                    <td>Shows access-time distribution when timestamps are available, identifying files
                        that may be candidates for archiving rather than migration.</td>
                    <td><span class="tag tag-green">Included</span></td>
                </tr>
                <tr>
                    <td><strong>Scan control (stop/pause/resume)</strong></td>
                    <td>Stop and Pause buttons provide immediate control over the scan. If interrupted,
                        the scan resumes from where it left off on the next run ‚Äî completed stages are
                        skipped and partially-processed data is not repeated. Safe for very large datasets
                        that may require multiple sessions to complete.</td>
                    <td><span class="tag tag-green">Included</span></td>
                </tr>
            </table>

            <div class="callout callout-green">
                <strong>‚úÖ All previously identified limitations have been addressed.</strong>
                Every item from the original roadmap is now implemented and appears in the HTML report.
                Optional features (content hashing, alternate data stream scanning) are enabled by ticking
                a checkbox in the application, giving full control over scan duration and disk read activity.
            </div>
        </div>

        <!-- ============================================================ -->
        <div class="section">
            <h2>Typical Runtime Workflow</h2>
            <ol>
                <li><strong>Copy the application</strong> onto the file server. It is a single file ‚Äî no installer,
                    no dependencies, no .NET or Java runtime required.</li>
                <li><strong>Right-click and choose "Run as Administrator"</strong> to ensure full
                    access to NTFS security descriptors and the open-files API. The application opens and
                    <strong>automatically
                        detects the local environment</strong>: all fixed drives (C:\, D:\, etc.), the domain
                    controller,
                    and DFS namespace paths are pre-filled based on system configuration. No manual data entry is needed
                    in most cases.
                </li>
                <li><strong>Select any optional features</strong> (such as content hashing or alternate data
                    stream
                    scanning) and press Start. The scan runs automatically through all stages with a live
                    progress display. <strong>Stop</strong> and <strong>Pause</strong> buttons are always available
                    to immediately halt or temporarily suspend the scan at any point ‚Äî the tool responds within
                    seconds even during heavy parallel processing.
                    If the scan is interrupted (stopped, paused, or the application is closed), it can be
                    <strong>resumed
                        from where it left off</strong> simply by running it again with the same output folder ‚Äî
                    completed stages are automatically skipped and partially-completed work is not repeated.
                    A benchmark run across 2 million files completed inventory in under 35 seconds on local NVMe.
                    Production elapsed time varies by file count, storage performance, and selected options. All I/O is
                    local disk ‚Äî no network traffic for file enumeration.
                </li>
                <li><strong>All data stays on the server.</strong> The scan results (database, CSV exports,
                    and HTML report) are written to an output folder on the server for later collection.</li>
                <li><strong>Open the HTML report</strong> directly from the application, or in any web browser ‚Äî no
                    special software needed. The report button is right there on screen once the scan completes.</li>
                <li><strong>Repeat for each file server</strong>, then optionally run
                    <strong>compare-db</strong> in the CLI to find duplicates spanning environments.
                    This generates a dedicated cross-server CSV and HTML report.
                </li>
                <li><strong>Use the findings</strong> to decide what to migrate, what to archive, and what to clean
                    up ‚Äî <em>before</em> incurring cloud storage costs.</li>
            </ol>

            <div class="callout callout-green">
                <strong>üéØ Zero-Configuration Startup</strong>
                The application automatically detects your local drives, domain controller, and DFS namespaces
                on startup, pre-filling the form with sensible defaults. In most cases, you can simply press Start
                without entering any information manually. Advanced options remain available for custom scenarios.
            </div>

            <div class="callout callout-amber">
                <strong>üîë Administrator Access</strong>
                The application should be run as Administrator (right-click ‚Üí "Run as administrator") on
                each file server. This ensures it can read all NTFS security descriptors regardless of
                file permissions, and detect which files are currently open by users. Without elevation, the
                application still works but may miss some permission data and will skip open-file detection.
            </div>
        </div>

        <!-- ============================================================ -->
        <div class="section">
            <h2>Next Steps</h2>
            <ol>
                <li>Identify the file servers to scan and the output folder location for each run.</li>
                <li>Schedule a maintenance window or agree to run during business hours (the core scan has minimal
                    impact; optional content hashing is more I/O-intensive and can be scheduled separately).</li>
                <li>Log in to each file server with a domain admin or local admin account, copy the application
                    across, and run it as Administrator. No service account, installation, or special
                    configuration is needed ‚Äî it is a single file with a graphical interface.</li>
                <li>Copy the output (database, CSV exports, and HTML report) off the server for review.</li>
                <li>Review the reports together and agree on the migration scope, archiving strategy, and cleanup plan.
                </li>
            </ol>

            <div class="callout callout-blue">
                <strong>Questions?</strong>
                This document is intended as a high-level overview. A full technical specification covering the scan
                stages, database schema, and output formats is available on request.
            </div>
        </div>

    </div>

    <footer>
        FSAnalyser ‚Äî File Server Analysis Tool &bull; Prepared by Steve Watson &bull; February 2026
    </footer>

</body>

</html>